from faster_whisper import WhisperModel
import os
from pydub import AudioSegment
import tempfile

print("üéß –ó–∞–≥—Ä—É–∑–∫–∞ Faster-Whisper –º–æ–¥–µ–ª–∏...")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å "base" —Å CPU - –±—ã—Å—Ç—Ä–µ–µ –∏ –ª–µ–≥—á–µ —á–µ–º openai-whisper
model = WhisperModel("base", device="cpu", compute_type="int8")

print("‚úÖ Faster-Whisper –≥–æ—Ç–æ–≤!")

def transcribe_audio(audio_file_path):
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
    
    Args:
        audio_file_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
    
    Returns:
        str: —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    wav_path = None
    
    try:
        print(f"üéß –ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {audio_file_path}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ pydub –≤ WAV 16kHz mono (—Ç–æ —á—Ç–æ –Ω—É–∂–Ω–æ Whisper)
        print("üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—é –∞—É–¥–∏–æ...")
        audio = AudioSegment.from_file(audio_file_path)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞—É–¥–∏–æ
        duration = len(audio) / 1000.0  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        print(f"üìä –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫, –ö–∞–Ω–∞–ª—ã: {audio.channels}, Sample rate: {audio.frame_rate}")
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –Ω–∞ 10 –¥–ë (–Ω–∞ —Å–ª—É—á–∞–π —Ç–∏—Ö–æ–≥–æ –∞—É–¥–∏–æ)
        audio = audio + 10
        
        # Whisper —Ç—Ä–µ–±—É–µ—Ç: 16kHz, mono
        audio = audio.set_frame_rate(16000).set_channels(1)
        
        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV —Ñ–∞–π–ª
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        wav_path = temp_wav.name
        temp_wav.close()
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
        audio.export(wav_path, format="wav")
        print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {wav_path}")
        
        print(f"üéß –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å —á–µ—Ä–µ–∑ Faster-Whisper...")

        # Faster-Whisper API: transcribe –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (segments, info)
        segments, info = model.transcribe(
            wav_path,
            language="en",
            beam_size=5,
            vad_filter=True  # –§–∏–ª—å—Ç—Ä –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        )

        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        text_parts = []
        segment_count = 0
        for segment in segments:
            text_parts.append(segment.text.strip())
            segment_count += 1
            if segment_count <= 3:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å–µ–≥–º–µ–Ω—Ç–∞
                print(f"  Segment {segment_count}: '{segment.text.strip()}'")

        text = " ".join(text_parts).strip()

        if text:
            print(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{text}'")
            print(f"üìù –í—Å–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {segment_count}")
        else:
            print("‚ö†Ô∏è Whisper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É")
            print(f"‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ –ù–ï –ø—É—Å—Ç–æ–µ –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥—Ä–æ–º–∫–æ–µ")
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV
        if wav_path and os.path.exists(wav_path):
            try:
                os.remove(wav_path)
            except:
                pass
        
        return text if text else None
        
    except Exception as e:
        print(f"‚ùå Whisper error: {e}")
        import traceback
        traceback.print_exc()
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV
        if wav_path and os.path.exists(wav_path):
            try:
                os.remove(wav_path)
            except:
                pass
        
        return None